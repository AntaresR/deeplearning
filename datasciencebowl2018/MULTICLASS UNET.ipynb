{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.utils import *\n",
    "from dataset.dataset import *\n",
    "from dataset.transform import *\n",
    "from model.loss import *\n",
    "from model.unet import UNet256_3x3\n",
    "from training.classifier import NucleiClassifier\n",
    "from model.eval import *\n",
    "from dataset.submission import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage.morphology import label\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create Random (Stratified) Train and Validation Set - RUN AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes = pd.read_csv('classes.csv')\n",
    "train_dirs, valid_dirs = get_stratified_valid_dirs(classes, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_path = '../data/ds_bowl_2018/'\n",
    "full_path = '../data/ds_bowl_2018/full_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "create_validation_dirs(main_path, full_path, None, train_dirs, valid_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test distribution\n",
    "classes[~classes.is_train].groupby(['foreground', 'background']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# distributions seem similar to test\n",
    "classes[classes.filename.isin([f + '.png' for f in valid_dirs])].groupby(['foreground', 'background']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Prep\n",
    "\n",
    "In multiclass UNET we will not be outputing a single channel like we did for binary classification background or mask but rather this time we will have a 3 channel output. Each channel will correspond to probability distributions for background, mask and overlap. We will be using multiclass BCE Loss.\n",
    "\n",
    "Output Channels:\n",
    "\n",
    "- Background\n",
    "- Foreground\n",
    "- Overlap\n",
    "\n",
    "\n",
    "If there are 3 unique pixel intensities\n",
    "\n",
    "- 30 : Background\n",
    "- 110 : Nuclei\n",
    "- 215 : Overlap Boundary\n",
    "\n",
    "If there are 2 unique pixel intensities\n",
    "\n",
    "- 30 : Background\n",
    "- 215 : Nuclei\n",
    "\n",
    "w_background, w_nuclei, w_overlap = (1.1551767249306626, 7.544967099214484, 557.753645718466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/ds_bowl_2018/train/'\n",
    "valid_path = '../data/ds_bowl_2018/valid/'\n",
    "dummy_path = '../data/ds_bowl_2018/dummy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = list_directory(train_path)\n",
    "valid_dirs = list_directory(valid_path)\n",
    "dummy_dirs = list_directory(dummy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_directory(train_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dirs), len(valid_dirs), len(dummy_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_mask(mask):\n",
    "    if len(np.unique(mask)) == 2:\n",
    "        back_channel = (mask == 30)*1 # background\n",
    "        nuclei_channel = (mask == 215)*1 # nuclei\n",
    "        overlap_channel = np.zeros_like(mask) # overlap - missing so all 0s\n",
    "    else:\n",
    "        back_channel = (mask == 30)*1 # background\n",
    "        nuclei_channel = (mask == 110)*1 # nuclei\n",
    "        overlap_channel = (mask == 215)*1 # overlap\n",
    "    # stack depth-wise\n",
    "    multiclass_mask = np.dstack([back_channel, nuclei_channel, overlap_channel])\n",
    "    return multiclass_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augment(image, mask, index, sz = 256):           \n",
    "    # get 3d mask\n",
    "    mask3d = get_3d_mask(mask).astype(np.uint8) \n",
    "    # resize image, mask for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    mask3d = fix_resize_transform(mask3d, sz, sz) \n",
    "    # get dimensions right for pytorch\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    mask3d = (mask3d.transpose((2,0,1)))\n",
    "    return image.astype(np.float64), mask3d.astype(np.float64), index\n",
    "\n",
    "def valid_augment(image, mask, index, sz = 256):        \n",
    "    # get 3d mask\n",
    "    mask3d = get_3d_mask(mask).astype(np.uint8) \n",
    "    # resize image, mask for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    mask3d = fix_resize_transform(mask3d, sz, sz) \n",
    "    # get dimensions right for pytorch\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    mask3d = (mask3d.transpose((2,0,1)))\n",
    "    return image.astype(np.float64), mask3d.astype(np.float64), index\n",
    "\n",
    "\n",
    "def test_augment(image, mask, index, sz = 256):\n",
    "    # resize image for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    # normalize pixel intensities\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    return image.astype(np.float64), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dummyloader\n",
    "dummy_ds = NucleiDataset('../data/ds_bowl_2018/dummy/', transform=train_augment, mode='train', mask_file='/mclass_one_mask.png')\n",
    "dummy_dl = DataLoader(dummy_ds, batch_size=1, shuffle=False)\n",
    "# create trainloader\n",
    "trn_ds = NucleiDataset('../data/ds_bowl_2018/train/', transform=train_augment, mode='train', mask_file='/mclass_one_mask.png')\n",
    "trn_dl = DataLoader(trn_ds, batch_size=16, shuffle=True)\n",
    "# create validloader.png\n",
    "val_ds = NucleiDataset('../data/ds_bowl_2018/valid/', transform=valid_augment, mode='valid', mask_file='/mclass_one_mask.png')\n",
    "val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "# create testloader\n",
    "test_ds = NucleiDataset('../data/ds_bowl_2018/test/', transform=test_augment, mode='test')\n",
    "test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighted_BCELoss2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Weights for a single sample which is repeated along the batch\n",
    "    Inputs:\n",
    "        weight: weigth tensor for a single sample\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None):\n",
    "        super(Weighted_BCELoss2d, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # contruct bce loss\n",
    "        batch_size = targets.size(0)\n",
    "        weights = self.weight.repeat(batch_size)\n",
    "        bce_loss = nn.BCELoss(weights)\n",
    "        # calc loss\n",
    "        probs        = F.softmax(logits, dim=1)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        return bce_loss(probs_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_background, w_nuclei, w_overlap = (1.155, 7.544, 557.753)\n",
    "weights = torch.cat([torch.ones(256*256)*w_background, \n",
    "                     torch.ones(256*256)*w_nuclei, torch.ones(256*256)*w_overlap]).double().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training definition\n",
    "net = UNet256_3x3(in_shape=(3, 256, 256), num_classes=3).double().cuda()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.01)\n",
    "# weighted BCELoss\n",
    "crit = Weighted_BCELoss2d(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init classifier\n",
    "classifier = NucleiClassifier(net, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train for 10 epochs\n",
    "classifier.train(train_loader=trn_dl, valid_loader=val_dl, optimizer=optimizer,crit=crit, epochs=100, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.save_model('./models/mclass38', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.restore_model('./models/mclass38')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate by Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_side_to_side(im1, im2, figsize=(13, 13)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(im2)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = NucleiDataset('../data/ds_bowl_2018/valid/', transform=valid_augment, mode='valid', mask_file='/mclass_one_mask.png')\n",
    "val_dl = DataLoader(val_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask, _ = next(it)\n",
    "\n",
    "net = classifier.net.eval()\n",
    "\n",
    "out = net(V(img).cuda())\n",
    "\n",
    "prob, idx = torch.max(out, 1)\n",
    "\n",
    "show_with_sz(idx.cpu().data.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_sz(img[0].numpy().transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
