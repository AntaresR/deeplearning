{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.utils import *\n",
    "from dataset.dataset import *\n",
    "from dataset.transform import *\n",
    "from model.loss import *\n",
    "from model.unet import UNet256_3x3\n",
    "from training.classifier import NucleiClassifier\n",
    "from model.eval import *\n",
    "from dataset.submission import *\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from skimage.morphology import label\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Create Random (Stratified) Train and Validation Set - RUN AS NEEDED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "classes = pd.read_csv('classes.csv')\n",
    "train_dirs, valid_dirs = get_stratified_valid_dirs(classes, seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "main_path = '../data/ds_bowl_2018/'\n",
    "full_path = '../data/ds_bowl_2018/full_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied 606 training and 64 validation data\n"
     ]
    }
   ],
   "source": [
    "create_validation_dirs(main_path, full_path, None, train_dirs, valid_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreground</th>\n",
       "      <th>background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">purple</th>\n",
       "      <th>purple</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yellow</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  is_train\n",
       "foreground background                    \n",
       "purple     purple             1         1\n",
       "           white              3         3\n",
       "           yellow             8         8\n",
       "white      black             53        53"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test distribution\n",
    "classes[~classes.is_train].groupby(['foreground', 'background']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreground</th>\n",
       "      <th>background</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">purple</th>\n",
       "      <th>purple</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <th>black</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename  is_train\n",
       "foreground background                    \n",
       "purple     purple             2         2\n",
       "           white              4         4\n",
       "white      black             58        58"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distributions seem similar to test\n",
    "classes[classes.filename.isin([f + '.png' for f in valid_dirs])].groupby(['foreground', 'background']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Prep\n",
    "\n",
    "In multiclass UNET we will not be outputing a single channel like we did for binary classification background or mask but rather this time we will have a 3 channel output. Each channel will correspond to probability distributions for background, mask and overlap. We will be using multiclass BCE Loss.\n",
    "\n",
    "Output Channels:\n",
    "\n",
    "- Background\n",
    "- Foreground\n",
    "- Overlap\n",
    "\n",
    "\n",
    "If there are 3 unique pixel intensities\n",
    "\n",
    "- 30 : Background\n",
    "- 110 : Nuclei\n",
    "- 215 : Overlap Boundary\n",
    "\n",
    "If there are 2 unique pixel intensities\n",
    "\n",
    "- 30 : Background\n",
    "- 215 : Nuclei\n",
    "\n",
    "w_background, w_nuclei, w_overlap = (1.1551767249306626, 7.544967099214484, 557.753645718466)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/ds_bowl_2018/train/'\n",
    "valid_path = '../data/ds_bowl_2018/valid/'\n",
    "dummy_path = '../data/ds_bowl_2018/dummy/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dirs = list_directory(train_path)\n",
    "valid_dirs = list_directory(valid_path)\n",
    "dummy_dirs = list_directory(dummy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/ds_bowl_2018/train/e4537e7893e631f3ba6ae5b1023e24b233c78249a31c2f5e561f6c4cad88fcf6/mclass_one_mask.png/',\n",
       " '../data/ds_bowl_2018/train/e4537e7893e631f3ba6ae5b1023e24b233c78249a31c2f5e561f6c4cad88fcf6/masks/',\n",
       " '../data/ds_bowl_2018/train/e4537e7893e631f3ba6ae5b1023e24b233c78249a31c2f5e561f6c4cad88fcf6/images/']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_directory(train_dirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(606, 64, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dirs), len(valid_dirs), len(dummy_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3d_mask(mask):\n",
    "    if len(np.unique(mask)) == 2:\n",
    "        back_channel = (mask == 30)*1 # background\n",
    "        nuclei_channel = (mask == 215)*1 # nuclei\n",
    "        overlap_channel = np.zeros_like(mask) # overlap - missing so all 0s\n",
    "    else:\n",
    "        back_channel = (mask == 30)*1 # background\n",
    "        nuclei_channel = (mask == 110)*1 # nuclei\n",
    "        overlap_channel = (mask == 215)*1 # overlap\n",
    "    # stack depth-wise\n",
    "    multiclass_mask = np.dstack([back_channel, nuclei_channel, overlap_channel])\n",
    "    return multiclass_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_augment(image, mask, index, sz = 256):           \n",
    "    # get 3d mask\n",
    "    mask3d = get_3d_mask(mask).astype(np.uint8) \n",
    "    # resize image, mask for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    mask3d = fix_resize_transform(mask3d, sz, sz) \n",
    "    # get dimensions right for pytorch\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    mask3d = (mask3d.transpose((2,0,1)))\n",
    "    return image.astype(np.float64), mask3d.astype(np.float64), index\n",
    "\n",
    "def valid_augment(image, mask, index, sz = 256):        \n",
    "    # get 3d mask\n",
    "    mask3d = get_3d_mask(mask).astype(np.uint8) \n",
    "    # resize image, mask for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    mask3d = fix_resize_transform(mask3d, sz, sz) \n",
    "    # get dimensions right for pytorch\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    mask3d = (mask3d.transpose((2,0,1)))\n",
    "    return image.astype(np.float64), mask3d.astype(np.float64), index\n",
    "\n",
    "\n",
    "def test_augment(image, mask, index, sz = 256):\n",
    "    # resize image for Unet256\n",
    "    image = fix_resize_transform(image, sz, sz)\n",
    "    # normalize pixel intensities\n",
    "    image = (image.transpose((2,0,1))) / 255 \n",
    "    return image.astype(np.float64), index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dummyloader\n",
    "dummy_ds = NucleiDataset('../data/ds_bowl_2018/dummy/', transform=train_augment, mode='train', mask_file='/mclass_one_mask.png')\n",
    "dummy_dl = DataLoader(dummy_ds, batch_size=1, shuffle=False)\n",
    "# create trainloader\n",
    "trn_ds = NucleiDataset('../data/ds_bowl_2018/train/', transform=train_augment, mode='train', mask_file='/mclass_one_mask.png')\n",
    "trn_dl = DataLoader(trn_ds, batch_size=16, shuffle=True)\n",
    "# create validloader.png\n",
    "val_ds = NucleiDataset('../data/ds_bowl_2018/valid/', transform=valid_augment, mode='valid', mask_file='/mclass_one_mask.png')\n",
    "val_dl = DataLoader(val_ds, batch_size=16, shuffle=False)\n",
    "# create testloader\n",
    "test_ds = NucleiDataset('../data/ds_bowl_2018/test/', transform=test_augment, mode='test')\n",
    "test_dl = DataLoader(test_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weighted_BCELoss2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Weights for a single sample which is repeated along the batch\n",
    "    Inputs:\n",
    "        weight: weigth tensor for a single sample\n",
    "    \"\"\"\n",
    "    def __init__(self, weight=None):\n",
    "        super(Weighted_BCELoss2d, self).__init__()\n",
    "        self.weight = weight\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # contruct bce loss\n",
    "        batch_size = targets.size(0)\n",
    "        weights = self.weight.repeat(batch_size)\n",
    "        bce_loss = nn.BCELoss(weights)\n",
    "        # calc loss\n",
    "        probs        = F.softmax(logits, dim=1)\n",
    "        probs_flat   = probs.view (-1)\n",
    "        targets_flat = targets.view(-1)\n",
    "        return bce_loss(probs_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_background, w_nuclei, w_overlap = (1.155, 7.544, 557.753)\n",
    "weights = torch.cat([torch.ones(256*256)*w_background, \n",
    "                     torch.ones(256*256)*w_nuclei, torch.ones(256*256)*w_overlap]).double().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training definition\n",
    "net = UNet256_3x3(in_shape=(3, 256, 256), num_classes=3).double().cuda()\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.1)\n",
    "optimizer = optim.RMSprop(net.parameters(), lr=0.1)\n",
    "# weighted BCELoss\n",
    "crit = Weighted_BCELoss2d(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init classifier\n",
    "classifier = NucleiClassifier(net, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\n",
      "Training : [2.5705],Validation : [3.0883]\n",
      "Epoch: 22\n",
      "Training : [2.9707],Validation : [2.2333]\n",
      "Epoch: 23\n",
      "Training : [2.6349],Validation : [2.0003]\n",
      "Epoch: 24\n",
      "Training : [2.7624],Validation : [2.1028]\n",
      "Epoch: 25\n",
      "Training : [2.6743],Validation : [1.8726]\n",
      "Epoch: 26\n",
      "Training : [2.6271],Validation : [1.9951]\n",
      "Epoch: 27\n",
      "Training : [2.6622],Validation : [2.1075]\n",
      "Epoch: 28\n",
      "Training : [2.6003],Validation : [3.1161]\n",
      "Epoch: 29\n",
      "Training : [2.573],Validation : [3.0118]\n",
      "Epoch: 30\n",
      "Training : [2.6178],Validation : [2.4611]\n",
      "saving at 10\n",
      "Epoch: 31\n",
      "Training : [2.6216],Validation : [3.418]\n",
      "Epoch: 32\n",
      "Training : [2.4947],Validation : [2.8201]\n",
      "Epoch: 33\n",
      "Training : [2.4566],Validation : [1.9171]\n",
      "Epoch: 34\n",
      "Training : [2.526],Validation : [1.9593]\n",
      "Epoch: 35\n",
      "Training : [2.5589],Validation : [2.2711]\n",
      "Epoch: 36\n",
      "Training : [2.438],Validation : [1.8514]\n",
      "Epoch: 37\n",
      "Training : [2.5089],Validation : [1.7949]\n",
      "Epoch: 38\n",
      "Training : [2.4422],Validation : [1.747]\n",
      "Epoch: 39\n",
      "Training : [2.491],Validation : [1.8385]\n",
      "Epoch: 40\n",
      "Training : [2.4496],Validation : [1.9189]\n",
      "saving at 20\n",
      "Epoch: 41\n",
      "Training : [2.431],Validation : [1.7809]\n",
      "Epoch: 42\n",
      "Training : [2.4448],Validation : [2.1961]\n",
      "Epoch: 43\n",
      "Training : [2.372],Validation : [1.9787]\n",
      "Epoch: 44\n",
      "Training : [2.3487],Validation : [1.7266]\n",
      "Epoch: 45\n",
      "Training : [2.3536],Validation : [1.6557]\n",
      "Epoch: 46\n",
      "Training : [2.3666],Validation : [1.9184]\n",
      "Epoch: 47\n",
      "Training : [2.3641],Validation : [1.7008]\n",
      "Epoch: 48\n",
      "Training : [2.2915],Validation : [1.8139]\n",
      "Epoch: 49\n",
      "Training : [2.326],Validation : [1.6705]\n",
      "Epoch: 50\n",
      "Training : [2.3822],Validation : [2.231]\n",
      "saving at 30\n",
      "Epoch: 51\n",
      "Training : [2.3581],Validation : [1.8111]\n",
      "Epoch: 52\n",
      "Training : [2.3277],Validation : [1.8415]\n",
      "Epoch: 53\n",
      "Training : [2.2869],Validation : [1.6981]\n",
      "Epoch: 54\n",
      "Training : [2.2578],Validation : [1.6195]\n",
      "Epoch: 55\n",
      "Training : [2.2506],Validation : [1.6989]\n",
      "Epoch: 56\n",
      "Training : [2.2682],Validation : [1.6736]\n",
      "Epoch: 57\n",
      "Training : [2.2297],Validation : [1.6959]\n",
      "Epoch: 58\n",
      "Training : [2.2589],Validation : [1.5534]\n",
      "Epoch: 59\n",
      "Training : [2.2627],Validation : [1.7876]\n",
      "Epoch: 60\n",
      "Training : [2.199],Validation : [1.579]\n",
      "saving at 40\n",
      "Epoch: 61\n",
      "Training : [2.2046],Validation : [1.9506]\n",
      "Epoch: 62\n",
      "Training : [2.1307],Validation : [1.635]\n",
      "Epoch: 63\n",
      "Training : [2.203],Validation : [1.5245]\n",
      "Epoch: 64\n",
      "Training : [2.0949],Validation : [1.7574]\n",
      "Epoch: 65\n",
      "Training : [2.3915],Validation : [1.6954]\n",
      "Epoch: 66\n",
      "Training : [2.1844],Validation : [1.7063]\n",
      "Epoch: 67\n",
      "Training : [2.1133],Validation : [1.623]\n",
      "Epoch: 68\n",
      "Training : [2.093],Validation : [1.9431]\n",
      "Epoch: 69\n",
      "Training : [2.1407],Validation : [1.6564]\n",
      "Epoch: 70\n",
      "Training : [2.1517],Validation : [1.5451]\n",
      "saving at 50\n",
      "Epoch: 71\n",
      "Training : [2.1178],Validation : [1.6942]\n",
      "Epoch: 72\n",
      "Training : [2.1473],Validation : [1.5054]\n",
      "Epoch: 73\n",
      "Training : [2.0204],Validation : [1.6024]\n",
      "Epoch: 74\n",
      "Training : [2.0235],Validation : [1.5391]\n",
      "Epoch: 75\n",
      "Training : [2.2099],Validation : [1.6443]\n",
      "Epoch: 76\n",
      "Training : [2.0256],Validation : [1.7521]\n",
      "Epoch: 77\n",
      "Training : [2.0392],Validation : [1.504]\n",
      "Epoch: 78\n",
      "Training : [2.0128],Validation : [6.4044]\n",
      "Epoch: 79\n",
      "Training : [2.088],Validation : [1.7651]\n",
      "Epoch: 80\n",
      "Training : [1.9736],Validation : [2.3836]\n",
      "saving at 60\n",
      "Epoch: 81\n",
      "Training : [2.3623],Validation : [1.6175]\n",
      "Epoch: 82\n",
      "Training : [1.9858],Validation : [1.7023]\n",
      "Epoch: 83\n",
      "Training : [1.9218],Validation : [1.5152]\n",
      "Epoch: 84\n",
      "Training : [1.9757],Validation : [1.5217]\n",
      "Epoch: 85\n",
      "Training : [1.9747],Validation : [1.6133]\n",
      "Epoch: 86\n",
      "Training : [1.9409],Validation : [1.4884]\n",
      "Epoch: 87\n",
      "Training : [1.9046],Validation : [1.5112]\n",
      "Epoch: 88\n",
      "Training : [1.86],Validation : [1.8664]\n",
      "Epoch: 89\n",
      "Training : [1.9534],Validation : [2.745]\n",
      "Epoch: 90\n",
      "Training : [1.9038],Validation : [1.8766]\n",
      "saving at 70\n",
      "Epoch: 91\n",
      "Training : [1.9018],Validation : [1.6667]\n"
     ]
    }
   ],
   "source": [
    "# train for 10 epochs\n",
    "for i in range(10):\n",
    "    classifier.train(train_loader=trn_dl, valid_loader=val_dl, optimizer=optimizer,crit=crit, epochs=10, threshold=0.5)\n",
    "    print(f'saving at {(i+1)*10}')\n",
    "    classifier.save_model(f'./models/mclass_{(i+1)*10}', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate by Eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_side_to_side(im1, im2, figsize=(13, 13)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(im1)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(im2)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = NucleiDataset('../data/ds_bowl_2018/valid/', transform=valid_augment, mode='valid', mask_file='/mclass_one_mask.png')\n",
    "val_dl = DataLoader(val_ds, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, mask, _ = next(it)\n",
    "\n",
    "net = classifier.net.eval()\n",
    "\n",
    "out = net(V(img).cuda())\n",
    "\n",
    "prob, idx = torch.max(out, 1)\n",
    "\n",
    "show_with_sz(idx.cpu().data.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_sz(img[0].numpy().transpose((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
