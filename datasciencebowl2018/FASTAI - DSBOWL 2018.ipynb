{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicating fastai caravana challenge notebook for datascience bowl\n",
    "\n",
    "\n",
    "- Predict Multiclass\n",
    "- Get boundary + interior - dilation(boundary)\n",
    "- Watershed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../fastai/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "#torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/ds_bowl_2018/')\n",
    "paths = list(PATH.iterdir())\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = 'stage1_train' \n",
    "TEST_DN = 'stage2_test_final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_csv = pd.read_csv(paths[0])\n",
    "masks_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUCLEI_ID = '58406ed8ef944831c413c3424dc2b07e59aef13eb1ff16acbb3402b38b5de0bd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((PATH/TRAIN_DN).iterdir())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUCLEI_IDS = [str(TRAIN_DIR).split('/')[-1] for TRAIN_DIR in list((PATH/TRAIN_DN).iterdir())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(PATH/TRAIN_DN/f'{NUCLEI_ID}/images/{NUCLEI_ID}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(PATH/TRAIN_DN/f'{NUCLEI_ID}/multiclass_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ims = [open_image(PATH/TRAIN_DN/f'{NUCLEI_ID}/images/{NUCLEI_ID}.png')\n",
    "       for NUCLEI_ID in NUCLEI_IDS[:16]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 4, figsize=(9, 6))\n",
    "for i,ax in enumerate(axes.flat): show_img(ims[i], ax=ax)\n",
    "plt.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOTAL NUMBER OF IMAGES WITH MASK LABELS\n",
    "n = len(list((PATH/TRAIN_DN).iterdir()))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DN = Path('../data/ds_bowl_2018/stage1_train/')\n",
    "TEST_DN = Path('../data/ds_bowl_2018/stage2_test_final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIRS = list(TRAIN_DN.iterdir())\n",
    "TEST_DIRS = list(TEST_DN.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilesDataset(BaseDataset):\n",
    "    def __init__(self, fnames, transform, path):\n",
    "        self.path,self.fnames = path,fnames\n",
    "        super().__init__(transform)\n",
    "    def get_sz(self): return self.transform.sz\n",
    "    def get_x(self, i): return open_image(os.path.join(self.path, self.fnames[i]))\n",
    "    def get_n(self): return len(self.fnames)\n",
    "\n",
    "    def resize_imgs(self, targ, new_path):\n",
    "        dest = resize_imgs(self.fnames, targ, self.path, new_path)\n",
    "        return self.__class__(self.fnames, self.y, self.transform, dest)\n",
    "\n",
    "    def denorm(self,arr):\n",
    "        \"\"\"Reverse the normalization done to a batch of images.\n",
    "\n",
    "        Arguments:\n",
    "            arr: of shape/size (N,3,sz,sz)\n",
    "        \"\"\"\n",
    "        if type(arr) is not np.ndarray: arr = to_np(arr)\n",
    "        if len(arr.shape)==3: arr = arr[None]\n",
    "        return self.transform.denorm(np.rollaxis(arr,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_im = cv2.imread(str(TRAIN_DN/f'{NUCLEI_ID}/multiclass_mask.png'), cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((test_im == 215)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_y(y, y_sz = None):\n",
    "    y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    multi_y = np.dstack([(y == 30)*1, # back\n",
    "    (y == 110)*1, # fore\n",
    "    (y == 215)*1]).transpose(2,0,1) # bound\n",
    "    if y_sz is not None:\n",
    "        multi_y = np.array([cv2.resize(y.astype(np.uint8), (y_sz, y_sz)) for y in multi_y])\n",
    "    return multi_y.astype(np.float32)\n",
    "\n",
    "class NucleiDataset(FilesDataset):\n",
    "    def __init__(self, fnames, y, transform, path, y_sz=256):\n",
    "        self.y_sz = y_sz\n",
    "        self.y=y\n",
    "        super().__init__(fnames, transform, path)\n",
    "    def get_y(self, i): return get_multi_y(self.y[i], self.y_sz)\n",
    "    def get_c(self): return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_X = [str(x_name/'images'/x_name.name) + '.png' for x_name in TRAIN_DIRS]\n",
    "TRAIN_Y = [str(x_name/'multiclass_mask.png') for x_name in TRAIN_DIRS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to give dummy TEST_Y path - THIS IS A HACK NOT AN ABSOLUTE SOLUTION\n",
    "TEST_X = [str(x_name/'images'/x_name.name) + '.png' for x_name in TEST_DIRS]\n",
    "TEST_Y = np.random.choice(TRAIN_Y, len(TEST_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_X = [TRAIN_X[0]]\n",
    "VAL_Y = [TRAIN_Y[0]]\n",
    "TRN_X  = TRAIN_X\n",
    "TRN_Y = TRAIN_Y"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# create trn, val data\n",
    "from dataset.validation import *\n",
    "\n",
    "classes = pd.read_csv('classes.csv')\n",
    "train_dirs, valid_dirs = get_stratified_valid_dirs(classes, seed=17)\n",
    "\n",
    "TRN_X = [s for s in TRAIN_X if s.split('/')[-1].split('.')[0] in train_dirs]\n",
    "VAL_X = [s for s in TRAIN_X if s.split('/')[-1].split('.')[0] not in train_dirs]\n",
    "TRN_Y = [s for s in TRAIN_Y if s.split('/')[-2] in train_dirs]\n",
    "VAL_Y = [s for s in TRAIN_Y if s.split('/')[-2] not in train_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(TRN_X), len(TRN_Y), len(VAL_X), len(VAL_Y), len(TEST_X), len(TEST_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRN_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Data\n",
    "\n",
    "Using Imagenet stats or others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model function\n",
    "PATH = '../data/'\n",
    "f = resnet18\n",
    "sz = 256\n",
    "bs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats = [0, 1] # no normalize\n",
    "#tfms = tfms_from_stats(stats, sz, crop_type=CropType.NO, tfm_y=None) # non-imagenet stats\n",
    "tfms = tfms_from_model(f, sz, crop_type=CropType.NO, tfm_y=None) # imagenet stats\n",
    "dataset = ImageData.get_ds(NucleiDataset, (TRN_X, TRN_Y), (VAL_X, VAL_Y), tfms=tfms, test= (TEST_X, TEST_Y), path=PATH)\n",
    "md = ImageData(PATH, dataset, bs, num_workers=16, classes=None)\n",
    "denorm = md.trn_ds.denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.trn_dl))\n",
    "x_np, y_np = to_np(x[0]), to_np(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np.min(), x_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_image(TRN_X[0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np.min(), y_np.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(denorm(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = to_np(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = to_np(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_np[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_np[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(md.test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dyanmic UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.models.unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load defined model\n",
    "def get_encoder(f, cut):\n",
    "    base_model = (cut_model(f(True), cut))\n",
    "    return nn.Sequential(*base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODER: RESNET18\n",
    "\n",
    "Has `extra_block` to output the original image size\n",
    "\n",
    "Steps of creating a Dynamic Unet Model:\n",
    "\n",
    "- Choose your encoder model or define it yourself (make sure it's downsampling as H, W -> H//2, W//2)\n",
    "- Initialize DynamicUnet as m = DynamicUnet(encoder)\n",
    "- In order to get the model to gpu set m = m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = resnet18\n",
    "cut, cut_lr = model_meta[f]\n",
    "cut, cut_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??cut_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??get_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(f, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DynamicUnet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.ones(1, 3, 256, 256)\n",
    "out = m(V(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.sfs_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODER: RESNET50\n",
    "\n",
    "Has `extra_block` to output the original image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = resnet50\n",
    "cut, cut_lr = model_meta[f]\n",
    "cut, cut_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(f, cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DynamicUnet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.ones(1, 3, 256, 256)\n",
    "out = m(V(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODER: VGG16 \n",
    "\n",
    "Doesn't have `extra_block`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = vgg16\n",
    "cut, cut_lr = model_meta[f]\n",
    "cut, cut_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_encoder(f, 30)\n",
    "m = DynamicUnet(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.ones(1, 3, 256, 256)\n",
    "out = m(V(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_loss(pred,targ):\n",
    "    return F.binary_cross_entropy_with_logits(pred[:,0],targ[...,0])\n",
    "\n",
    "def mask_acc(pred,targ): return accuracy_multi(pred[:,0], targ[...,0], 0.)\n",
    "\n",
    "def dice(pred, targs):\n",
    "    m1 = (pred[:,0]>0).float()\n",
    "    m2 = targs[...,0]\n",
    "    return 2. * (m1*m2).sum() / (m1+m2).sum()\n",
    "\n",
    "def multi_acc(logits, targets):\n",
    "    bs, c, h, w = logits.size()\n",
    "    out2 = logits.view(bs,c,h*w).transpose(2,1).contiguous()\n",
    "    input_ = out2.view(bs*h*w,c)\n",
    "\n",
    "    # target for cross entropy\n",
    "    _, idx = torch.max(targets, 1)\n",
    "    target = idx.view(-1)\n",
    "\n",
    "    return sum(torch.max(input_, dim=1)[1] == target) / len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since I am training on multiclass data, loss_fn will be different\n",
    "class MulticlassBCELoss2d(nn.Module):\n",
    "    \"\"\"\n",
    "    Weights for a single sample which is repeated along the batch\n",
    "    Inputs:\n",
    "        weight: weigth tensor for a single sample\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MulticlassBCELoss2d, self).__init__()\n",
    "        \n",
    "    def forward(self, logits, targets):\n",
    "        # input for cross entropy\n",
    "        bs, c, h, w = logits.size()\n",
    "        out2 = logits.view(bs,c,h*w).transpose(2,1).contiguous()\n",
    "        input_ = out2.view(bs*h*w,c)\n",
    "        \n",
    "        # target for cross entropy\n",
    "        _, idx = torch.max(targets, 1)\n",
    "        target = idx.view(-1)\n",
    "        return F.cross_entropy(input_, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loss and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ = torch.stack([torch.ones(3,3)*0, torch.ones(3,3)*0, torch.ones(3,3)], dim=0)[None, :]\n",
    "inp = torch.stack([torch.ones(3,3)*0.3, torch.ones(3,3)*0.3, torch.ones(3,3)*0.4], dim=0)[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagine all ground truth is class 2\n",
    "# output logits are given\n",
    "inp, targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = MulticlassBCELoss2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(V(inp), V(targ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(V(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax(.., ..., 0.400) = (..., ..., 0.3559)\n",
    "- np.log(0.3559)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_acc(inp, targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put everything together + Training (ResNet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) Define wrapper model class for Fast.ai Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap everything nicely\n",
    "class UpsampleModel():\n",
    "    def __init__(self, model, cut_lr, name='upsample'):\n",
    "        self.model,self.name, self.cut_lr = model, name, cut_lr\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.encoder), [self.cut_lr]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Define Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = vgg16\n",
    "cut, cut_lr = model_meta[f]\n",
    "cut, cut_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Specify Cut and Init DynamicUnet\n",
    "\n",
    "Put model to gpu if you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder = get_encoder(f, 30).cpu()\n",
    "m = DynamicUnet(encoder.cpu()).cpu()\n",
    "\n",
    "# create a dummy input - I couldn't find a work around for this to co-op with cpu - gpu tensor weight\n",
    "# incosistencies so it's best to make a single forward pass ourselves if we want to use the gpu\n",
    "# otherwise it will be fine on cpu\n",
    "inp = torch.ones(1,3,256,256)\n",
    "out = m(V(inp).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Put to GPU (Optional) - Check Decoder Network\n",
    "\n",
    "You will see `extra_block` for ResNet like architecture where downsample happens in first activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for p in list(m.parameters()):\n",
    "    print(p.get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Wrap DynamicUnet to be Fast.ai Ready\n",
    "\n",
    "`cut_lr` will be used to group layers for freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify layer groups pre-freezing\n",
    "# cut_lr is experimental and heavily dependent on data you have, let's try 9\n",
    "models = UpsampleModel(m, cut_lr=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5) Create learn object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(md, models)\n",
    "learn.opt_fn=optim.Adam\n",
    "learn.crit = MulticlassBCELoss2d()\n",
    "learn.metrics=[multi_acc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6) Check your layers to make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learn.models.get_layer_groups(False)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze first 3 conv bn relu\n",
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "learn.fit(lr,1,cycle_len=16,use_clr_beta=(10,10, 0.85, 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = learn.predict_dl(md.test_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERIOR + BOUNDARY - EROSION(BOUNDARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax_preds = [np.argmax(pred, 0) for pred in test_preds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WATERSHED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pred = argmax_preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('coins.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise removal\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# sure background area\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=3) # DILATION(FORE + BOUND)\n",
    "\n",
    "# Finding sure foreground area\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# Finding unknown region\n",
    "sure_fg = np.uint8(sure_fg) # FORE\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marker labelling\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "# Add one to all labels so that sure background is not 0, but 1\n",
    "markers = markers+1\n",
    "\n",
    "# Now, mark the region of unknown with zero\n",
    "markers[unknown==255] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(argmax_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_szs = [open_image(fn).shape[:-1] for fn in md.test_ds.fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_szs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_argmax_preds = [np.clip(cv2.resize(pred.astype(np.uint8), sz), 0, 2) for sz, pred in zip(test_szs, argmax_preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watershed_preds= []\n",
    "\n",
    "for sample_pred in resized_argmax_preds:\n",
    "    sure_back = np.uint8((sample_pred > 0))\n",
    "\n",
    "    sure_fore = np.uint8(sample_pred == 1)\n",
    "\n",
    "    unknown = cv2.subtract(sure_back,sure_fore)\n",
    "\n",
    "    ret, markers = cv2.connectedComponents(sure_fore)\n",
    "\n",
    "    markers = markers + 1\n",
    "\n",
    "    markers[unknown==255] = 0\n",
    "\n",
    "    watershed_preds.append(markers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_to_rles(x, cutoff=0.5):\n",
    "    \"\"\"takes probability mask and yields for generator by looping over all labels\"\"\"\n",
    "    lab_img = x\n",
    "    for i in range(1, lab_img.max() + 1):\n",
    "        yield rle_encoding(lab_img == i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission_df(preds, test_ds, rle_func=ws_to_rles):\n",
    "    \"\"\"\n",
    "    Takes resized preds and ta\n",
    "    est dataset\n",
    "    to return rle df\n",
    "    Inputs:\n",
    "        preds (list): list of np.arrays which has 2d binary mask predictions\n",
    "        test_ds (Dataset): test dataset\n",
    "        rle_func (function): function to encode each binary mask prediction with run length encoding\n",
    "    Return:\n",
    "        sub (pd.dataframe): pandas dataframe for submission\n",
    "    \"\"\"\n",
    "    new_test_ids = []\n",
    "    rles = []\n",
    "    for n, id_ in enumerate(test_ds.fnames):\n",
    "        id_ = id_.split('/')[-2]\n",
    "        rle = list(rle_func(preds[n]))\n",
    "        rles.extend(rle)\n",
    "        new_test_ids.extend([id_] * len(rle))\n",
    "\n",
    "    sub = pd.DataFrame()\n",
    "    sub['ImageId'] = new_test_ids\n",
    "    sub['EncodedPixels'] = pd.Series(rles).apply(lambda x: ' '.join(str(y) for y in x))\n",
    "    return sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encoding(x):\n",
    "    dots = np.where(x.T.flatten() == 1)[0]\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = get_submission_df(watershed_preds, md.test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./final_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FileLink('./final_sub.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
