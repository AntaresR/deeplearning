{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LeNet\n",
    "- AlexNet\n",
    "- VGG16\n",
    "- ResNet\n",
    "- GoogLeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GoogLeNet:**\n",
    "\n",
    "**Inception Modules:** Parallel convs with different sizes,then concatenated depth wise. Compuationally very expensive.\n",
    "\n",
    "**Solution**: Bottleneck Layers, add 1x1 conv with lower dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNet**: Extremely Deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though deeper models are expected to give better results it's not\n",
    "the case. As we increase depth of a NN like VGG or AlexNet from 20 layers to 50 layers. 50 layer network performs worse in both training and validation data. The reaason is that deeper models are harder to optimize. Because a deeper model should at least perform as good as the less complex model on training data.\n",
    "\n",
    "As networks get deeper it's getting harder to learn H(x) which is the next activation after conv and relu by the input x. Rather than trying to learn H(x) we will learn F(x)+ x where F(x) is the residual function of x. How much we need to tweak are previous input. Author's hyothesis is that this is easier to learn than H(x) for example Identity mappings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training ResNet in Practice:**\n",
    "\n",
    "- Batch Normalization\n",
    "- Xavier/2 initialization\n",
    "- SGD + Momentum (0.9)\n",
    "- Learning rate 0.1 divided by 10 when val error plateus\n",
    "- Mini Batch Size 256\n",
    "- Weight Decay 1e-5\n",
    "- No Dropout Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Nets**\n",
    "\n",
    "- ResNext\n",
    "- Stochastic Dropout\n",
    "- SqueezeNet (AlexNet Performance with 50x less params)\n",
    "- FractalNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
